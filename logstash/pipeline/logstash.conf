#filebeat 사용 선언 및 수신할 IP와 포트 지정
input {
	beats {
		port => 5044
	}
	http {
		port => 5011
		codec => "line"
	}
	udp {
		port => 5012
		codec => "json"
	}
	tcp {
		port => 5013
		codec => "json_lines"
	}
}

## Add your filters / logstash plugins configuration here
# grok 형식으로 들어오는 로그를 가공하기 위해 필터 사용
# 메시지 필드를 공용 Nginx 로그로 변환하고 접속지의 IP를 기반으로 정보 가공 내용 추가하기
filter {
    if "nginx" in [tags]{
        grok {
            match => { "message" => "%{COMMONAPACHELOG}" }
             }
        geoip {
            source => "clientip"
            target => "geoip"
              }
       }
}

# Logstash의 가공한 정보를 어디에 출력할지 설정
# 모든 데이터를 elk-%{+YYYY.MM.dd}라는 이름의 인덱스를 만들어서 Elasticsearch로 보내도록 설정
output {
	elasticsearch {
		# hosts => "elasticsearch:9200"
		# hosts => "odfe-node1:9200"
		hosts => ["https://odfe-node1:9200"] 
    	ssl => true
    	ssl_certificate_verification => false
		user => "admin"
		password => "admin"
		ilm_enabled => false
		# ecs_compatibility => disabled
		index => "elk-%{+YYYY.MM.dd}"
	}
}
